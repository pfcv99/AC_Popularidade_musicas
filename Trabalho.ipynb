{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor de Popularidade de Músicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Índice**<a id='toc0_'></a>    \n",
    "1. [Introdução](#toc1_)    \n",
    "2. [Preparação do notebook para R e Python em sumultâneo](#toc2_)    \n",
    "3. [Importação dos módulos](#toc3_)    \n",
    "4. [Exploração dos dados em bruto](#toc4_)    \n",
    "4.1. [Upload dos dados](#toc4_1_)    \n",
    "4.2. [Criação do dataframe](#toc4_2_)    \n",
    "4.3. [Visualização do dataframe em bruto e de algumas métricas](#toc4_3_)    \n",
    "5. [Análise Exploratória](#toc5_)    \n",
    "5.1. [Distribuição dos valores em cada coluna](#toc5_1_)    \n",
    "6. [Pré-processamento dos dados](#toc6_)    \n",
    "6.1. [Identificação de Valores Ausentes](#toc6_1_)    \n",
    "6.2. [Remoção de musicas com tempo 0](#toc6_2_)    \n",
    "6.3. [Identificação e remoção de duplicados](#toc6_3_)    \n",
    "6.4. [Definir o índice](#toc6_4_)    \n",
    "6.5. [Remover coluna song_name](#toc6_5_)    \n",
    "6.6. [Definir variáveis categóricas e variáveis numéricas](#toc6_6_)    \n",
    "6.7. [Método do intervalo interquartil (IQR) para filtrar outliers](#toc6_7_)    \n",
    "6.8. [Remoção de outliers com o z-score](#toc6_8_)    \n",
    "6.9. [Remoção de outliers com Local Outlier Factor (LOF)](#toc6_9_)    \n",
    "6.10. [Remoção de outliers variável a variável](#toc6_10_)    \n",
    "6.11. [Gráficos comparativos da remoção dos outliers com os diferentes métodos](#toc6_11_)    \n",
    "6.12. [Inferência](#toc6_12_)    \n",
    "6.13. [Estatísticas do dataset](#toc6_13_)    \n",
    "6.14. [Divisão das variáveis dependentes e independentes](#toc6_14_)    \n",
    "7. [Divisão em conjunto de treino e conjunto de teste](#toc7_)    \n",
    "8. [Implementação de algoritmos de Aprendizagem Computacional](#toc8_)    \n",
    "8.1. [Random Forest](#toc8_1_)    \n",
    "8.1.1. [Treino inicial do modelo](#toc8_1_1_)    \n",
    "8.1.2. [Matriz de confusão](#toc8_1_2_)    \n",
    "8.1.3. [Afinação dos hiperparâmetros com o Grid Search Cross Validation](#toc8_1_3_)    \n",
    "8.1.4. [Configurar e executar o Grid Search Cross Validation](#toc8_1_4_)    \n",
    "8.1.5. [Treino do modelo com os melhores hiperparâmetros](#toc8_1_5_)    \n",
    "9. [Resultados](#toc9_)    \n",
    "10. [Considerações finais](#toc10_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=true\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a id='toc1_'></a>[Introdução](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a id='toc2_'></a>[Preparação do notebook para R e Python em sumultâneo](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! R -e \"install.packages('IRkernel', repos = 'http://cran.us.r-project.org');IRkernel::installspec()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install rpy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%R -i df_no_outliers\n",
    "#head(df_no_outliers) #Exemplo de utilização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a id='toc3_'></a>[Importação dos módulos](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. <a id='toc4_'></a>[Exploração dos dados em bruto](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. <a id='toc4_1_'></a>[Upload dos dados](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/song_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. <a id='toc4_2_'></a>[Criação do dataframe](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. <a id='toc4_3_'></a>[Visualização do dataframe em bruto e de algumas métricas](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. <a id='toc5_'></a>[Análise Exploratória](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. <a id='toc5_1_'></a>[Distribuição dos valores em cada coluna](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = df_raw.columns\n",
    "\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_counts = {}\n",
    "\n",
    "for col in col_names:\n",
    "    col_counts[col] = df_raw[col].value_counts()\n",
    "\n",
    "col_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. <a id='toc6_'></a>[Pré-processamento dos dados](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. <a id='toc6_1_'></a>[Identificação de Valores Ausentes](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. <a id='toc6_2_'></a>[Remoção de musicas com tempo 0](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.drop(df_raw[(df_raw['tempo']==0)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. <a id='toc6_3_'></a>[Identificação e remoção de duplicados](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover duplicatas considerando todas as colunas\n",
    "df_raw.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4. <a id='toc6_4_'></a>[Definir o índice](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.set_index(pd.RangeIndex(start=1, stop=len(df_raw)+1, step=1), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5. <a id='toc6_5_'></a>[Remover coluna song_name](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.drop(columns='song_name', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6. <a id='toc6_6_'></a>[Definir variáveis categóricas e variáveis numéricas](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector as selector\n",
    "numerical_columns_selector = selector(dtype_exclude='category')\n",
    "categorical_columns_selector = selector(dtype_include='category')\n",
    "\n",
    "numerical_columns = numerical_columns_selector(X)\n",
    "categorical_columns = categorical_columns_selector(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler() \n",
    "scaled_values = scaler.fit_transform(df_raw) \n",
    "df_raw.loc[:,:] = scaled_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.7. <a id='toc6_7_'></a>[Método do intervalo interquartil (IQR) para filtrar outliers](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df_raw.select_dtypes(include='number')\n",
    "\n",
    "# Calcula Q1, Q3 e IQR para cada coluna numérica\n",
    "Q1 = numeric_columns.quantile(0.25)\n",
    "Q3 = numeric_columns.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define os limites para identificar outliers\n",
    "lower_bound = Q1 - 1.5 * IQR \n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identifica e remove outliers\n",
    "outliers = ((numeric_columns < lower_bound) | (numeric_columns > upper_bound)).any(axis=1)\n",
    "df_IQR = df_raw[~outliers]\n",
    "df_IQR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.8. <a id='toc6_8_'></a>[Remoção de outliers com o z-score](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular os z-scores para todas as colunas\n",
    "z_scores = np.abs(stats.zscore(df_raw))\n",
    "\n",
    "# Definir um threshold para outliers (por exemplo, Z-score < 3)\n",
    "threshold = 3\n",
    "\n",
    "# Manter as linhas onde os z-scores são menores que o threshold para todas as colunas\n",
    "df_Z = df_raw[(z_scores < threshold).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.9. <a id='toc6_9_'></a>[Remoção de outliers com Local Outlier Factor (LOF)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Supondo que df_raw é o seu DataFrame carregado com várias colunas\n",
    "# Se df_raw não estiver definido, você pode carregá-lo assim:\n",
    "# df_raw = pd.read_csv('caminho/para/seu/arquivo.csv')\n",
    "\n",
    "# Load the dataset\n",
    "X = df_raw\n",
    "\n",
    "# Create the LocalOutlierFactor model for outlier detection\n",
    "lof_outlier = LocalOutlierFactor(n_neighbors=20)\n",
    "\n",
    "# Fit the model to the data and predict the outlier scores for each data point\n",
    "outlier_scores = lof_outlier.fit_predict(X)\n",
    "\n",
    "# Identify the outlier data points\n",
    "outlier_indices = outlier_scores == -1\n",
    "print(\"Outlier indices:\", outlier_indices)\n",
    "\n",
    "# Remover os outliers do DataFrame\n",
    "df_LOF = X[~outlier_indices]\n",
    "df_LOF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.10. <a id='toc6_10_'></a>[Remoção de outliers variável a variável](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.11. <a id='toc6_11_'></a>[Gráficos comparativos da remoção dos outliers com os diferentes métodos](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms and boxplots for each variable in a single image\n",
    "variables = X.columns\n",
    "num_vars = len(variables)\n",
    "\n",
    "fig, axes = plt.subplots(num_vars, 2, figsize=(14, 5*num_vars))\n",
    "\n",
    "for i, variable in enumerate(variables):\n",
    "    # Histogram with and without outliers\n",
    "    sns.histplot(X[variable], bins=50, kde=True, color='blue', ax=axes[i, 0], label='Original')\n",
    "    sns.histplot(df_LOF[variable], bins=50, kde=True, color='orange', ax=axes[i, 0], label='LOF')\n",
    "    sns.histplot(df_Z[variable], bins=50, kde=True, color='green', ax=axes[i, 0], label='Z-score')\n",
    "    sns.histplot(df_IQR[variable], bins=50, kde=True, color='red', ax=axes[i, 0], label='IRQ')\n",
    "    axes[i, 0].set_title(f'{variable} - Histogram')\n",
    "    axes[i, 0].legend()\n",
    "\n",
    "    # Boxplot with and without outliers\n",
    "    sns.boxplot(data=[X[variable], df_LOF[variable]], ax=axes[i, 1])\n",
    "    axes[i, 1].set_xticklabels(['With Outliers', 'Without Outliers'])\n",
    "    axes[i, 1].set_title(f'{variable} - Boxplot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2022)\n",
    "x = np.random.randn(100)\n",
    "\n",
    "f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "\n",
    "sns.boxplot(x=x, ax=ax_box)\n",
    "sns.histplot(x=x, bins=12, kde=True, stat='density', ax=ax_hist)\n",
    "\n",
    "ax_box.set(yticks=[])\n",
    "sns.despine(ax=ax_hist)\n",
    "sns.despine(ax=ax_box, left=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.12. <a id='toc6_12_'></a>[Inferência](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conjunto de dados inicial: 18835 amostras.\n",
    "\n",
    "Com o método do Intervalo Interquartil: \n",
    "\n",
    "Com o método do Z-score:\n",
    "\n",
    "Com o método do Local Outlier Factor:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.13. <a id='toc6_13_'></a>[Estatísticas do dataset](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Definindo as cores\n",
    "colors = ['green', 'red']  # Exemplo de cores: azul e laranja\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))  # Criando uma figura com 3 subplots\n",
    "\n",
    "# Gráfico para df_IQR\n",
    "axes[0].set_title('Método IQR')\n",
    "axes[0].pie([df_IQR.shape[0], df_raw.shape[0] - df_IQR.shape[0]],\n",
    "            radius=1,\n",
    "            labels=['Mantido', 'Excluído'],\n",
    "            counterclock=False,\n",
    "            autopct='%1.1f%%',\n",
    "            pctdistance=0.9,\n",
    "            explode=[0.02, 0],\n",
    "            shadow=False,\n",
    "            colors=colors)  # Adicionando a lista de cores\n",
    "\n",
    "# Gráfico para df_Z\n",
    "axes[1].set_title('Método Z-score')\n",
    "axes[1].pie([df_Z.shape[0], df_raw.shape[0] - df_Z.shape[0]],\n",
    "            radius=1,\n",
    "            labels=['Mantido', 'Excluído'],\n",
    "            counterclock=False,\n",
    "            autopct='%1.1f%%',\n",
    "            pctdistance=0.9,\n",
    "            explode=[0.02, 0],\n",
    "            shadow=False,\n",
    "            colors=colors)  # Adicionando a lista de cores\n",
    "\n",
    "# Gráfico para df_LOF\n",
    "axes[2].set_title('Método LOF')\n",
    "axes[2].pie([df_LOF.shape[0], df_raw.shape[0] - df_LOF.shape[0]],\n",
    "            radius=1,\n",
    "            labels=['Mantido', 'Excluído'],\n",
    "            counterclock=False,\n",
    "            autopct='%1.1f%%',\n",
    "            pctdistance=0.9,\n",
    "            explode=[0.02, 0],\n",
    "            shadow=False,\n",
    "            colors=colors)  # Adicionando a lista de cores\n",
    "\n",
    "plt.tight_layout()  # Ajusta o layout para evitar sobreposição de legendas\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.14. <a id='toc6_14_'></a>[Divisão das variáveis dependentes e independentes](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data intro training & testing sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#m=[]\n",
    "#for i in df_IQR.columns.values:\n",
    "#    m.append(i.replace(' ','_'))\n",
    "#    \n",
    "#df_IQR.columns = m\n",
    "#X = df_IQR[['song_duration_ms', 'acousticness', 'danceability', 'energy', 'instrumentalness', 'key', 'liveness', 'loudness', 'audio_mode', 'speechiness', #'tempo', 'time_signature', 'audio_valence']]\n",
    "#X.loc[:, ['key', 'audio_mode', 'time_signature']] = X.loc[:, ['key', 'audio_mode', 'time_signature']].astype('category')\n",
    "#Y = df_IQR[\"song_popularity\"]\n",
    "\n",
    "\n",
    "\n",
    "#m=[]\n",
    "#for i in df_Z.columns.values:\n",
    "#    m.append(i.replace(' ','_'))\n",
    "#    \n",
    "#df_Z.columns = m\n",
    "#X = df_Z[['song_duration_ms', 'acousticness', 'danceability', 'energy', 'instrumentalness', 'key', 'liveness', 'loudness', 'audio_mode', 'speechiness', 'tempo', #'time_signature', 'audio_valence']]\n",
    "#X.loc[:, ['key', 'audio_mode', 'time_signature']] = X.loc[:, ['key', 'audio_mode', 'time_signature']].astype('category')\n",
    "#Y = df_Z[\"song_popularity\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "m=[]\n",
    "for i in df_LOF.columns.values:\n",
    "    m.append(i.replace(' ','_'))\n",
    "    \n",
    "df_LOF.columns = m\n",
    "X = df_LOF[['song_duration_ms', 'acousticness', 'danceability', 'energy', 'instrumentalness', 'key', 'liveness', 'loudness', 'audio_mode', 'speechiness', 'tempo', 'time_signature', 'audio_valence']]\n",
    "X.loc[:, ['key', 'audio_mode', 'time_signature']] = X.loc[:, ['key', 'audio_mode', 'time_signature']].astype('category')\n",
    "Y = df_LOF[\"song_popularity\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. <a id='toc7_'></a>[Divisão em conjunto de treino e conjunto de teste](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "Train_X.reset_index(drop=True,inplace=True)\n",
    "\n",
    "print('Conjunto original (100%): ',X.shape,Y.shape,'\\nConjunto de treino (80%): ',Train_X.shape,Train_Y.shape,'\\nConjunto de teste (20%): ', Test_X.shape,'', Test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. <a id='toc8_'></a>[Implementação de algoritmos de Aprendizagem Computacional](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1. <a id='toc8_1_'></a>[Random Forest](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1.1. <a id='toc8_1_1_'></a>[Treino inicial do modelo](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import set_config\n",
    "\n",
    "# Escolha RandomForestClassifier para problemas de classificação e RandomForestRegressor para regressão\n",
    "model = make_pipeline(RandomForestRegressor(random_state=21))  # ou RandomForestRegressor\n",
    "set_config(display='diagram')\n",
    "\n",
    "# Treinar o modelo\n",
    "model.fit(Train_X, Train_Y)\n",
    "\n",
    "# Fazer previsões\n",
    "Pred_Y = model.predict(Test_X)\n",
    "model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelresults(predictions):\n",
    "    mae = mean_absolute_error(Test_Y, predictions)\n",
    "    mse = mean_squared_error(Test_Y, predictions)\n",
    "    r2 = r2_score(Test_Y, predictions)\n",
    "    \n",
    "    print('Erro absoluto médio do modelo: {:.4f}'.format(mae))\n",
    "    print('')\n",
    "    print('Erro quadrático médio do modelo: {:.4f}'.format(mse))\n",
    "    print('')\n",
    "    print('O valor de r2 do modelo: {:.4f}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelresults(Pred_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1.2. <a id='toc8_1_2_'></a>[Matriz de confusão](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1.3. <a id='toc8_1_3_'></a>[Afinação dos hiperparâmetros com o Grid Search Cross Validation](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],      # Número de árvores in the forest\n",
    "    'max_features': ['sqrt', 'log2'],     # Número de features a serem consideradas para divisão\n",
    "    'max_depth': [None, 10, 20, 30],      # Profundidade máxima da árvore\n",
    "    'min_samples_split': [2, 5, 10],      # Número mínimo de amostras para dividir um nó\n",
    "    'min_samples_leaf': [1, 2, 4]         # Número mínimo de amostras num nó folha\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1.4. <a id='toc8_1_4_'></a>[Configurar e executar o Grid Search Cross Validation](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar o GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=21), param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Executar o GridSearchCV\n",
    "grid_search.fit(Train_X, Train_Y)\n",
    "\n",
    "# Obter os melhores hiperparâmetros\n",
    "best_params = grid_search.best_params_\n",
    "best_estimator = grid_search.best_estimator_\n",
    "print(f\"Melhor estimador: {best_estimator}\")\n",
    "print(f'Melhores hiperparâmetros: {best_params}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.1.5. <a id='toc8_1_5_'></a>[Treino do modelo com os melhores hiperparâmetros](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um novo modelo com os melhores hiperparâmetros\n",
    "#best_model = RandomForestClassifier(**best_params, random_state=42)  # ou RandomForestRegressor\n",
    "best_model = RandomForestRegressor(**best_params, random_state=42)  # ou RandomForestRegressor\n",
    "\n",
    "# Treinar o modelo\n",
    "best_model.fit(Train_X, Train_Y)\n",
    "\n",
    "# Fazer previsões\n",
    "Best_Pred_Y = best_model.predict(Test_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelresults(Best_Pred_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "cm = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix(Best_Pred_Y, Pred_Y),\n",
    "                              display_labels=df_LOF.columns) \n",
    "cm.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. <a id='toc9_'></a>[Resultados](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. <a id='toc10_'></a>[Considerações finais](#toc0_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinformatics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
